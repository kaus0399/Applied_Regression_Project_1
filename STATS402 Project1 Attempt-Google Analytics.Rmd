---
title: "STATS402 Project1 Attempt:Google Analytics"
author: "Naiyu Niu, Kaustubh Deshpande, Jonathan Shan, Stephanie Lao"
date: "10/19/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# EDA
## a). Histograms of Numerical Variables
```{r}
library(car)

data <- read.csv("final_data.csv")
dt = sort(sample(nrow(data), nrow(data)*.70))
train<-data[dt,]
test<-data[-dt,]
sapply(train, class)
```
```{r}
hist(train$summedRevenue, 
     main = "Histogram of Original Data", xlab = "summedRevenue_log")

hist(log(train$summedRevenue_log), 
     main = "Histogram of Log-Transformed Data",
     xlab = "log of summedRevenue_log")
```

From the above plots, we can see that the original response variable is hard to analyze with a gigantic peak at the first bar. After we perform log-transformation, the distribution of the response variable resembles a normal distribution, where we could apply (generalized) linear models. 




# Models
- Full Model:
```{r}
full_mod <- lm(summedRevenue_log ~ avgGDP + factor(device.browser) + factor(device.operatingSystem) 
               + factor(device.deviceCategory) + factor(geoNetwork.continent) + factor(geoNetwork.subContinent) 
               + factor(geoNetwork.country) + totals.hits + totals.pageviews + factor(trafficSource.source),
               # + date
               # + trafficSource.adContent
               # + device.isMobile
               data = train)
```
- Model chosen by `step()` function: (the model with the least AIC)
```{r}
step_mod <- step(full_mod, direction = "both", steps = 100000)
summary(step_mod)
```
```{r}
plot(step_mod, which = 1)
plot(step_mod, which = 2)

residualPlots(step_mod)
```


- Manual selection
```{r}
# Only categorical variables
cat_mod <- aov(summedRevenue_log ~ device.browser + device.operatingSystem 
               + device.deviceCategory + geoNetwork.continent + geoNetwork.country 
               + trafficSource.source,
               data = train)
summary(cat_mod)

# Only numerical variables
num_mod <- lm(summedRevenue_log ~ avgGDP + totals.hits + totals.pageviews,
              data = train)
summary(num_mod)
```
```{r}
# see if device.deviceCategory is needed
try1 <- aov(summedRevenue_log ~ device.browser + device.operatingSystem
            + geoNetwork.continent + geoNetwork.country 
            + trafficSource.source,
            data = train)
try2 <- aov(summedRevenue_log ~ device.browser + device.operatingSystem 
            + device.deviceCategory + geoNetwork.continent + geoNetwork.country 
            + trafficSource.source,
            data = train)

anova(try1, try2)
```


From the p-value of F-test, we reject that the coefficient of device.deviceCategory is 0. 


```{r}
manual_mod <- lm(summedRevenue_log ~ avgGDP + factor(device.browser) 
                 + factor(device.operatingSystem) + factor(geoNetwork.continent) 
                 + factor(geoNetwork.subContinent) + factor(geoNetwork.country) 
                 + totals.hits + totals.pageviews + factor(trafficSource.source),
                 data = train)

# check if manual_mod wil be rejected
anova(manual_mod, step_mod)
```
The p-value is 0.7873>0.05. Hence, we fail to reject our manual model. 

```{r}
ncvTest(manual_mod)

plot(manual_mod, which = 1)
plot(manual_mod, which = 2)
```


```{r}
par(mfrow = c(1,2))

transaction_Mobile = train$summedRevenue_log[train$device.deviceCategory == "mobile"]
boxplot(transaction_Mobile)

transaction_notMobile = train$summedRevenue_log[train$device.deviceCategory != "mobile"]
boxplot(transaction_notMobile)

opar <- par()
```

```{r, eval=FALSE, echo=FALSE}
m <- lm(summedRevenue_log ~ device.operatingSystem + totals.hits + totals.pageviews + trafficSource.source, data = train)

summary(m)
ncvTest(m) # rejects equal variance, heteroskedasticity present
Box.test(m$residuals) # rejects normality
library(GeneCycle)
fisher.g.test(m$residuals) # fail to reject normality
# leveneTest(m)
#TukeyHSD(m)
```


```{r}
#Let's find the Robust standard errors
library(lmtest)
library(sandwich)
summary(step_mod)
coeftest(step_mod, vcov = vcovHC(step_mod, "HC1"))
```



Robust standard errors are much lower than the standard errors. This can be attributed to small sample size of positive transaction data points.
Regressing using these robust standard errors will solve the issue of computing incorrect interval estimates or incorrect values for our test statistics. However, we still have another issue from heteroskedasticity, that the regular OLS estimators no longer being best. If we had a large enough sample size the variance of the estimators may still be small enough to get precise estimates. However, since our sample size is relatively small the variance is much larger and we need to conduct some further analysis. Let's try using weighted least squares. 


```{r}
#Let's try weighted least squares
library(MASS)
resids <- step_mod$residuals
varfunc.step_mod <- lm(abs(resids)~factor(device.operatingSystem) + factor(device.deviceCategory) + 
    totals.hits, data = train)

weightz <- 1/((varfunc.step_mod$fitted.values)^2)

step_mod.wls = lm(summedRevenue_log~factor(device.operatingSystem) + factor(device.deviceCategory) + 
    totals.hits, weights = weightz, data = train)


summary(step_mod.wls)
# 
par(mfrow=c(1,2))
plot(step_mod, which = 1)
plot(step_mod.wls, which = 1)

par(mfrow=c(1,2))
plot(step_mod, which = 2)
plot(step_mod.wls, which = 2)

residualPlots(step_mod)
residualPlots(step_mod.wls)
```

```{r}

summary(step_mod)$r.squared
summary(step_mod.wls)$r.squared

# improvement of 0.30 or 600% 


y_hat <- predict(step_mod.wls,newdata = test)
residuals <- (test$summedRevenue_log - y_hat)
# 
RMSE <- sqrt(mean(residuals^2))
RMSE

# library(forecast)
# cor(residuals(step_mod)[-1], residuals(step_mod)[-length(residuals(step_mod))])
# checkresiduals(step_mod)
# 
# cor(residuals(step_mod.wls)[-1], residuals(step_mod)[-length(residuals(step_mod.wls))])
# checkresiduals(step_mod.wls)
```
```{r}


error_model_step <- rep(NA, 100)
error_model_step_wls <- rep(NA, 100)

for(i in 1:100){
   
   dt = sort(sample(nrow(data), nrow(data)*.75))
   train<-data[dt,]
   test<-data[-dt,]
   
   step_mod = lm(summedRevenue_log~factor(device.operatingSystem) + factor(device.deviceCategory) + 
   totals.hits, data = train)
   
   y_hat <- predict(step_mod,newdata = test)
   residuals <- (test$summedRevenue_log - y_hat)
   error_model_step[i] <- sqrt(mean(residuals^2))
   
   
   resids <- step_mod$residuals
   varfunc.step_mod <- lm(abs(resids)~factor(device.operatingSystem) + factor(device.deviceCategory) + 
   totals.hits, data = train)

   
   weightz <- 1/((varfunc.step_mod$fitted.values)^2)
   

   step_mod.wls = lm(summedRevenue_log~factor(device.operatingSystem) + factor(device.deviceCategory) + 
   totals.hits, weights = weightz, data = train)
   
   
   y_hat <- predict(step_mod.wls,newdata = test)
   residuals <- (test$summedRevenue_log - y_hat)
   error_model_step_wls[i] <- sqrt(mean(residuals^2))
  
}

mean(error_model_step)
mean(error_model_step_wls)
```







```{r}

# create vectors to store the validation errors for each model
# error_model1 <- rep(NA, 53)
# ...
error_model_step <- rep(NA, 1335)
error_model_step_wls <- rep(NA, 1335)

for(i in 1:1335){
  
  # write a line to select the ith line in the data
  # store this line as the 'test' case
  test <- data[i,]
  # store the remaining as the 'training' data
  train <- data[-c(i),]
  
  step_mod = lm(summedRevenue_log~factor(device.operatingSystem) + factor(device.deviceCategory) + 
   totals.hits, data = train)
  
  y_hat <- predict(step_mod,newdata = test)
  residuals <- (test$summedRevenue_log - y_hat)
  error_model_step[i] <- sqrt(mean(residuals^2))
  
  resids <- step_mod$residuals
  varfunc.step_mod <- lm(abs(resids)~factor(device.operatingSystem) + factor(device.deviceCategory) + 
   totals.hits, data = train)
  
  weightz <- 1/((varfunc.step_mod$fitted.values)^2)
  
  step_mod.wls = lm(summedRevenue_log~factor(device.operatingSystem) + factor(device.deviceCategory) + 
   totals.hits, weights = weightz, data = train)
  
  y_hat <- predict(step_mod.wls,newdata = test)
  residuals <- (test$summedRevenue_log - y_hat)
  error_model_step_wls[i] <- sqrt(mean(residuals^2))
  
 
}


# once all of the errors have been calculated, find the mean squared error
# ...
mean(error_model_step)
mean(error_model_step_wls)
```

